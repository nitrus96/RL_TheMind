{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_comm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZxR2y4xIxr8P5lx7grTAT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bByAgYwj84q-",
        "colab_type": "text"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T4ejPwM89n5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import random\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from torch import autograd\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpKzgNO_FeBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "78c7b37e-0245-41f7-a7ba-454766e1e186"
      },
      "source": [
        "### NB For some reason, the newest version of PyTorch does not calculate gradients properly ###\n",
        "\n",
        "!pip install torch==1.4.0 torchvision==0.5.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 22kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 34.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.18.5)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVDNOjxzlCox",
        "colab_type": "text"
      },
      "source": [
        "**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsSaXet0lB0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Environment settings\n",
        "HAND_SIZE = 2\n",
        "CARD_NUM = 50\n",
        "\n",
        "# Communication settings\n",
        "LEN_MESSAGE = 3\n",
        "\n",
        "# DQN learning parameters\n",
        "LR = 0.00003\n",
        "DISCOUNT = 0.5\n",
        "EXPLORATION_DECAY = 0.999\n",
        "EXPLORATION_RATE = 0.95"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5PPLvWf79M_",
        "colab_type": "text"
      },
      "source": [
        "**Environment**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mytQH7P88CFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TheMindEnv():\n",
        "\n",
        "    def __init__(self, hand_size=HAND_SIZE, card_num=CARD_NUM):\n",
        "        self.hand_size = hand_size\n",
        "        self.card_num = card_num\n",
        "        self.num_players = 2\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        # reset all attributes \n",
        "        self.cards_played = [] \n",
        "        self.last_action = [-1 for i in range(self.num_players)] # last action taken by the other other agent\n",
        "        self.agent_hand = np.array([np.zeros(self.hand_size) for i in range(self.num_players)], dtype='int64') # __repr__ like representation of agents' hands\n",
        "        self.dones = [False for i in range(self.num_players)] # keep track of agents' active status\n",
        "\n",
        "        self.info = False # if True, the epsiode was succesfully completed by all agents\n",
        "        self.actions_taken = [[] for i in range(self.num_players)] # keep track of actions taken in the episode\n",
        "        self.rew = [None for i in range(self.num_players)] # last reward\n",
        "        self.last_card = [None for i in range(self.num_players)] # last card played\n",
        "\n",
        "        get_cards = np.random.choice(np.arange(1,self.card_num+1), \n",
        "                                     self.num_players*self.hand_size, \n",
        "                                     replace=False) # draw and distribute cards among agents\n",
        "\n",
        "        for i in range(self.num_players):\n",
        "            hand = get_cards[i*self.hand_size:(i+1)*self.hand_size]\n",
        "            self.agent_hand[i] = hand # store actual card values\n",
        "\n",
        "        return self.agent_hand\n",
        "        \n",
        "    def step(self, actions): # actions is a list of agents' actions\n",
        "        self.last_action = actions\n",
        "        self.last_card = [0 for i in range(self.num_players)]\n",
        "        self.rew = [0 for r in range(self.num_players)] # init rewards for the timestep\n",
        "\n",
        "        for i, action in enumerate(actions):\n",
        "            # Place card on the table\n",
        "            if self.dones[i] == False:\n",
        "                # agent is playing a NEW card and not skipping their turn\n",
        "                if action not in self.actions_taken[i] and action < self.hand_size: \n",
        "                    card = self.agent_hand[i][action] # select card from agent's hand\n",
        "                    self.agent_hand[i][action] = 0\n",
        "                    self.rew[i] = 1\n",
        "                    self.actions_taken[i].append(action) # add action to history\n",
        "                    self.last_card[i] = card\n",
        "                    self.cards_played.append(card)\n",
        "            \n",
        "                if all(x==0 for x in self.agent_hand[i]): # if all cards are played, agent is DONE\n",
        "                    self.dones[i] = True\n",
        "        \n",
        "        ### Check that the rules of the table were not violated ###\n",
        "        cards_hands = np.array([i for p in self.agent_hand \n",
        "                                    for i in p if i != 0]) # gather cards across all agents\n",
        "        \n",
        "        if len(cards_hands) > 0:    \n",
        "            lowest = np.min(cards_hands)\n",
        "            for i, card in enumerate(self.last_card):\n",
        "                if card > lowest: # if card played is bigger than the smallest card across agents' hands, rules are violated\n",
        "                    self.dones = [True for a in range(self.num_players)]\n",
        "                    self.rew[i] = -1\n",
        "        else:\n",
        "            self.info = True\n",
        "        \n",
        "        return self.agent_hand, self.rew, self.dones, self.info\n",
        "\n",
        "    # print current game stats\n",
        "    def render(self): \n",
        "        for i in range(self.num_players):\n",
        "            print('Agent {} hand: {} \\nCard played: {}\\nAction index: {}\\n'.format(i+1, self.agent_hand[i],\n",
        "                                                                        self.last_card[i], self.last_action[i]))\n",
        "        print('Cards on the table: {}'.format(self.cards_played))\n",
        "        print('Rewards: {}'.format(self.rew))\n",
        "        print('Dones: {} \\n'.format(self.dones))\n",
        "        if all(self.dones):\n",
        "            print('##########################################\\n')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ban6-wP8RSd",
        "colab_type": "text"
      },
      "source": [
        "**Agent + Utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0M3DCZg8XYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecompDQN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim,\n",
        "                 card_embed_size = 64,\n",
        "                 message_embed_size = 128,\n",
        "                 gru_hidden = 256\n",
        "                ):       \n",
        "        super(DecompDQN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.card_embed_size = card_embed_size\n",
        "        self.message_embed_size = message_embed_size\n",
        "        self.gru_input = self.card_embed_size * HAND_SIZE + self.message_embed_size\n",
        "        self.gru_hidden = gru_hidden\n",
        "\n",
        "        self.card_embedding = nn.Embedding(input_dim+1, self.card_embed_size)\n",
        "\n",
        "        self.decode_message = nn.Sequential(\n",
        "            nn.Linear(LEN_MESSAGE, self.message_embed_size),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.q_layer = nn.Sequential(\n",
        "            nn.Linear(self.gru_hidden, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, self.output_dim + LEN_MESSAGE)\n",
        "        )\n",
        "\n",
        "        self.rnn = nn.GRU(input_size=self.gru_input,\n",
        "                          hidden_size=self.gru_hidden, \n",
        "                          num_layers=1\n",
        "        )\n",
        "\n",
        "    def to_embed(self, state):\n",
        "        return self.card_embedding(state).view(1,1,-1)\n",
        "\n",
        "    def forward(self, state, message, hidden):\n",
        "        # joint vector representation of hand + message\n",
        "        m = self.decode_message(message).view(1,1,-1)\n",
        "        x = torch.cat((state,m),2)\n",
        "\n",
        "        self.rnn.flatten_parameters()\n",
        "        out, h = self.rnn(x, hidden)\n",
        "\n",
        "        q_vals = self.q_layer(out).squeeze()\n",
        "        \n",
        "        # generate the message\n",
        "        m = torch.sigmoid(q_vals[-LEN_MESSAGE:].view(LEN_MESSAGE))\n",
        "\n",
        "        return q_vals[:self.output_dim], m, h\n",
        "    \n",
        "    # init RNN hidden state\n",
        "    def new_hidden(self):\n",
        "        h0 = torch.zeros(1, 1, self.gru_hidden).to(device)\n",
        "        return h0\n",
        "\n",
        "\n",
        "class Agent():\n",
        "\n",
        "    def __init__(self, obs_dim, action_space, ler=LR,\n",
        "                 discount=DISCOUNT, \n",
        "                 epsilon=EXPLORATION_RATE, eps_decay=EXPLORATION_DECAY):\n",
        "        \n",
        "        self.discount = discount\n",
        "        self.QNet = DecompDQN(obs_dim, action_space).to(device)\n",
        "        self.target_QNet = copy.deepcopy(self.QNet)\n",
        "        self.epsilon = epsilon\n",
        "        self.MSE_loss = nn.MSELoss()\n",
        "        self.optimizer = torch.optim.RMSprop(self.QNet.parameters(),\n",
        "                                             lr=ler,\n",
        "                                             momentum=0.9)\n",
        "        self.action_space = action_space\n",
        "        self.eps_decay = eps_decay\n",
        "    \n",
        "    # return action, its corresponding Q value, and updated RNN hidden state\n",
        "    def sample_action(self, state, message, hidden, action_filter):\n",
        "        self.epsilon *= self.eps_decay\n",
        "\n",
        "        q_vals, mes, h = self.QNet.forward(state, message, hidden) # forward pass through main network to get Q values and new hidden state\n",
        "                                   \n",
        "        if random.random() < self.epsilon: # random action\n",
        "            candidate_actions = [i for i in range(self.action_space) if i not in action_filter]\n",
        "            action = random.choice(candidate_actions)\n",
        "            return (q_vals[action], mes, action), h\n",
        "        else: # choose the action with the highest q value\n",
        "            q_vals[action_filter] = -10000 # so the action already taken wouldn't be selected\n",
        "            q_val, action = torch.max(q_vals,0)\n",
        "            return (q_val, mes, action.item()), h\n",
        "\n",
        "    # DQN algorithm\n",
        "    def train(self, obs):\n",
        "        # q: Q value at t; r: reward; n_s: observation at t+1; d: is the agent done?; n_h: hidden state at t+1\n",
        "        q, r, n_s, d, n_h, action_filter, n_m = obs\n",
        "        r = torch.FloatTensor([r]).to(device)\n",
        "        d = torch.FloatTensor([d]).to(device)\n",
        "\n",
        "        current_q = q.view(1) # Q value returned when sampling action\n",
        "        next_q, _ , _ = self.target_QNet.forward(n_s, n_m, n_h)\n",
        "        next_q[action_filter] = -10000\n",
        "        max_next_q = torch.max(next_q).item()\n",
        "        target_q = r + (self.discount*max_next_q*(1-d)) # target Q value obtained through target DQN net\n",
        "\n",
        "        loss = self.MSE_loss(current_q, target_q)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward(retain_graph=True)\n",
        "        self.optimizer.step()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkbDW6t19WPw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmiY6rid9aMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_DQN(episodes, print_info=False, plot_results=True, print_last=10):\n",
        "    env = TheMindEnv()\n",
        "    observation_space = env.card_num\n",
        "    action_space = env.hand_size + 1\n",
        "    num_episodes = episodes\n",
        "    completed_games = 0\n",
        "    scores = []\n",
        "\n",
        "    agents = Agent(obs_dim=observation_space, action_space=action_space)\n",
        "   \n",
        "    for episode in range(num_episodes+1):\n",
        "        observation = env.reset()\n",
        "        observation = [agents.QNet.to_embed(torch.LongTensor(o).view(1, env.hand_size).to(device))\n",
        "                       for o in observation] # convert observations to embeddings\n",
        "        messages = [torch.zeros(LEN_MESSAGE).to(device) for i in range(env.num_players)]\n",
        "        hidden = [agents.QNet.new_hidden() for i in range(env.num_players)] # init RNN hidden states\n",
        "        n_hidden = hidden.copy()\n",
        "        done_n = [False for _ in range(env.num_players)] # agents' active status\n",
        "\n",
        "        step = 0\n",
        "        \n",
        "        while not all(done_n) and step < 10:\n",
        "\n",
        "            if print_info:\n",
        "                if episode > episodes-print_last: \n",
        "                    env.render()\n",
        "                    print('Agent 1 message:', messages[1].data.cpu().numpy(),\n",
        "                          'Agent 2 message:', messages[0].data.cpu().numpy())\n",
        "                    print()\n",
        "\n",
        "            actions = []\n",
        "            qvals = []\n",
        "            n_messages = [] \n",
        "\n",
        "            for a in range(env.num_players):\n",
        "                action, h = agents.sample_action(observation[a], \n",
        "                                                 messages[a],\n",
        "                                                 hidden[a],\n",
        "                                                 env.actions_taken[a]) # get action for each agent\n",
        "                qvals.append(action[0]) # store Q value\n",
        "                n_messages.append(action[1])\n",
        "                actions.append(action[2]) # store action\n",
        "                n_hidden[a] = h # update RNN hidden state\n",
        "\n",
        "            n_observation, reward, done, info = env.step(actions) # take a step\n",
        "            n_observation = [agents.QNet.to_embed(torch.LongTensor(o).view(1, env.hand_size).to(device)) \n",
        "                             for o in n_observation] # convert observations to embeddings\n",
        "            n_messages = n_messages[::-1]\n",
        "                        \n",
        "            for a in range(env.num_players):\n",
        "                if done_n[a] is False:\n",
        "                    experience = (qvals[a], reward[a],\n",
        "                                  n_observation[a], done[a],\n",
        "                                  n_hidden[a], env.actions_taken[a],\n",
        "                                  n_messages[a])\n",
        "                    agents.train(experience) # update network parameters\n",
        "\n",
        "                    if done[a]: \n",
        "                        done_n[a] = True\n",
        "            \n",
        "            observation, hidden, messages = n_observation, n_hidden, n_messages\n",
        "            step+=1\n",
        "\n",
        "        if print_info:\n",
        "            if episode > episodes-print_last:\n",
        "                env.render()\n",
        "\n",
        "        if info == True:\n",
        "            completed_games += 1\n",
        "\n",
        "        # reset target Q net parameters every 50 episodes\n",
        "        if episode % 50 == 0:\n",
        "            agents.target_QNet.load_state_dict(agents.QNet.state_dict())\n",
        "\n",
        "        if episode % 100 == 0:\n",
        "            print('Episode {}: Solved {}% out of 100 games'.format(episode, completed_games))\n",
        "            scores.append(completed_games)\n",
        "            completed_games = 0\n",
        "\n",
        "    if plot_results:\n",
        "        plt.figure(figsize=(10,10))\n",
        "        plt.xticks(np.arange(0, num_episodes+1, 1000)) # plot every 1000\n",
        "        plt.yticks(np.arange(0, 100, 5))\n",
        "\n",
        "        x = np.linspace(0, num_episodes, len(scores))\n",
        "        y = np.array(scores)\n",
        "        f = interp1d(x, y, kind='quadratic')\n",
        "        x_new = np.linspace(0, num_episodes, len(scores)*4)\n",
        "        y_smooth = f(x_new)\n",
        "\n",
        "        plt.fill_between(x_new, y_smooth, y2=0, alpha=0.5)\n",
        "        plt.axis([0,episodes,0,100])\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    return agents\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otuMjCsXgOUs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "outputId": "e5d7e363-4f0f-4a0a-905c-06dc4a5314ce"
      },
      "source": [
        "train = run_DQN(2000)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 0: Solved 0% out of 100 games\n",
            "Episode 100: Solved 3% out of 100 games\n",
            "Episode 200: Solved 16% out of 100 games\n",
            "Episode 300: Solved 17% out of 100 games\n",
            "Episode 400: Solved 22% out of 100 games\n",
            "Episode 500: Solved 36% out of 100 games\n",
            "Episode 600: Solved 43% out of 100 games\n",
            "Episode 700: Solved 50% out of 100 games\n",
            "Episode 800: Solved 47% out of 100 games\n",
            "Episode 900: Solved 51% out of 100 games\n",
            "Episode 1000: Solved 58% out of 100 games\n",
            "Episode 1100: Solved 63% out of 100 games\n",
            "Episode 1200: Solved 60% out of 100 games\n",
            "Episode 1300: Solved 65% out of 100 games\n",
            "Episode 1400: Solved 59% out of 100 games\n",
            "Episode 1500: Solved 65% out of 100 games\n",
            "Episode 1600: Solved 65% out of 100 games\n",
            "Episode 1700: Solved 68% out of 100 games\n",
            "Episode 1800: Solved 62% out of 100 games\n",
            "Episode 1900: Solved 68% out of 100 games\n",
            "Episode 2000: Solved 62% out of 100 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}